{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incident-burden",
   "metadata": {
    "id": "equal-officer"
   },
   "source": [
    "# Repaso Módulo 1 y Módulo 2 \n",
    "\n",
    "En esta Notebook vamos a hacer un repaso de lo visto en la primera parte del curso. Vamos a realizar cada paso de un Proyecto de Ciencia de Datos:\n",
    "\n",
    "1. Definición del Problema\n",
    "2. Búsqueda de datos \n",
    "3. Exploración y Limpieza de Datos\n",
    "4. Dividisión de los datos en **X** (variables predictoras) e **y** (variable a predecir). División de los datos en entrenamiento y testo con el méodo *train_test_split*\n",
    "5. Entrenamiento del modelo\n",
    "6. Testeo del Modelo \n",
    "\n",
    "### Definición del problema\n",
    "\n",
    "**¿Cuál será la edad de una zarigüeya en base a determinadas características?**\n",
    "\n",
    "### Búsqueda de datos\n",
    "\n",
    "El dataset que se utilizará es sobre zarigüeyas, consta de nueve medidas morfométricas en 104 zarigüeyas, atrapadas en siete sitios desde el sur de Victoria hasta el centro de Queensland (Australia). En base a estas características es posible predecir la edad.\n",
    "Esta basado en el dataset descargable en [Kaggle](https://www.kaggle.com/abrambeyer/openintro-possum) pero tiene realizadas algunas modificaciones por lo que debe ser tomado desde el archivo csv descargado desde la plataforma. \n",
    "\n",
    "### Regresión\n",
    "\n",
    "Dado que la variable a predecir es numérica, el modelo de aprendizaje supervisado que entrenaremos será un modelo de **Regresión**, en este caso realizaremos una **Regresión Lineal Multiple** como hicimos en el Módulo 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iportamos las librerías que utilizaremos\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiremos data con el dataset con el método pd.read_csv\n",
    "\n",
    "data = pd.read_csv(\"dataset_zarigueya.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-cylinder",
   "metadata": {
    "id": "318vQ9fVipcw"
   },
   "source": [
    "## Exploración del dataset\n",
    "\n",
    "Realizaremos la primer exploración del dataset utilizando distintos métodos de la librería Pandas:\n",
    "- Los primero registros del Dataset\n",
    "- El tamaño del dataset\n",
    "- Los tipos de datos de las columnas\n",
    "- Las características de las variable numéricas\n",
    "- La correlación de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-newport",
   "metadata": {
    "id": "advisory-blackjack"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-nylon",
   "metadata": {},
   "source": [
    "#### Variable a predecir\n",
    "\n",
    "La variable a Predecir es *edad* por lo que realizaremos una pequeña exploración de esta variable con librería Pandas y realizando algunas visualizaciones con las librerías Matplotplib y Seaborn.\n",
    "\n",
    "- Mínimo valor de la columna\n",
    "- Máximo valor de la columna\n",
    "- Promedio de los valores de la columna (mean)\n",
    "- Gráfico displot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-savage",
   "metadata": {
    "id": "advisory-blackjack"
   },
   "outputs": [],
   "source": [
    "data[\"edad\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"edad\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"edad\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data[\"edad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-vehicle",
   "metadata": {},
   "source": [
    "### Limpieza de datos\n",
    "\n",
    "Realizaremos la limpieza de los datos con distintos métodos de la librería Pandas:\n",
    "- ELiminaremos columnas inecesarias para el entrenamiento del modelo\n",
    "- Realizaremos la limpieza de los datos nulos con algunas de las posibles estrategias: marcar, eliminar o imputar\n",
    "- Realizaremos la identificación y modificación de las variables categóricas\n",
    "\n",
    "##### Eliminar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"id\", \"populacion\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-gambling",
   "metadata": {
    "id": "GrnQUEpLoyEh"
   },
   "source": [
    "##### Limpieza de datos - nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-indie",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1646446722972,
     "user": {
      "displayName": "Valeria Bellino",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05918551666787590515"
     },
     "user_tz": 180
    },
    "id": "eligible-adapter",
    "outputId": "273e57ff-ac60-4219-f211-7a360f513280"
   },
   "outputs": [],
   "source": [
    "nulo_cabeza = data[\"cabeza\"].isnull()\n",
    "data.loc[nulo_cabeza]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-ensemble",
   "metadata": {
    "id": "outside-interest"
   },
   "outputs": [],
   "source": [
    "# Qué datos toma la variable\n",
    "\n",
    "data.dropna(axis=0, thresh=7, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-warrant",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646446750012,
     "user": {
      "displayName": "Valeria Bellino",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05918551666787590515"
     },
     "user_tz": 180
    },
    "id": "trying-australia",
    "outputId": "3206c2f0-33d1-4bd3-b540-9f619640af40"
   },
   "outputs": [],
   "source": [
    "# Comprobamos el tamaño del dataset y la cantidad de nulos\n",
    "\n",
    "print(data.shape)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-improvement",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646446869379,
     "user": {
      "displayName": "Valeria Bellino",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05918551666787590515"
     },
     "user_tz": 180
    },
    "id": "liable-bennett",
    "outputId": "0c56fe7d-1268-4460-d83d-9c4bcee2039a"
   },
   "outputs": [],
   "source": [
    "nulo_pie = data[\"pie\"].isnull()\n",
    "data.loc[nulo_pie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-frost",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1646446870622,
     "user": {
      "displayName": "Valeria Bellino",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05918551666787590515"
     },
     "user_tz": 180
    },
    "id": "increasing-cannon",
    "outputId": "5dd59aae-814b-4ac6-8e9a-edbd7790435e"
   },
   "outputs": [],
   "source": [
    "promedio = data[\"pie\"].mean()\n",
    "promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[nulo_pie, \"pie\"] = round(promedio,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-collector",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1646446898158,
     "user": {
      "displayName": "Valeria Bellino",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05918551666787590515"
     },
     "user_tz": 180
    },
    "id": "exact-portsmouth",
    "outputId": "b2e1f795-3241-4588-faa7-20b1d3c4c9f2"
   },
   "outputs": [],
   "source": [
    "# Comprobamos que este correctamente imputado y que no haya más datos nulos en lluvia\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-absence",
   "metadata": {
    "id": "RFFxUWo0pu1n"
   },
   "source": [
    "### Variables categóricas y numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data,  drop_first=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-method",
   "metadata": {
    "id": "5rC_FKtlhLOp"
   },
   "source": [
    "### Regresión Lineal Multiple\n",
    " \n",
    "Ahora que ya hemos realizado la exploración y limpieza del Dataset, vamos a entrenar unaRegresión Lineal Multiple como vimos en la primera parte del año, para poder generar un modelo que sirva para predecir la *edad* de las zarigüeyas.\n",
    "\n",
    "Realizaremos los siguientes pasos:\n",
    "\n",
    "1. Dividir los datos en **X** (variables predictoras) e **y** (variable a predecir)\n",
    "2. Dividir los datos en entrenamiento y testo con el méodo *train_test_split*\n",
    "3. Importar e instanciar el modelo que utilizaremos y definir hiperparámetros\n",
    "4. Entrenar el modelo con el método *fit*\n",
    "5. Testear el modelo con el método *predict*\n",
    "6. Ver la performance con una métrica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-salmon",
   "metadata": {
    "id": "XYqF03pmhTWc"
   },
   "outputs": [],
   "source": [
    "# Definimos X e y siendo X las variables predictoras e y la variable a predecir\n",
    "\n",
    "X=data.drop(columns=\"edad\")\n",
    "y=data[\"edad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-identity",
   "metadata": {
    "id": "skLvFQRJhTZK"
   },
   "outputs": [],
   "source": [
    "# Importamos train_test_split de la libreria scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-quantum",
   "metadata": {
    "id": "-5dCQg4-hTcw"
   },
   "outputs": [],
   "source": [
    "# Definimos X de entrenamiento y de testeo e y de entrenamiento y testeo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-northwest",
   "metadata": {
    "id": "JKRvlAlyht6m"
   },
   "outputs": [],
   "source": [
    "# Revisamos que esté correctamente realizada la operación\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-fields",
   "metadata": {
    "id": "EG0myRVfh0Pn"
   },
   "source": [
    "##### Entrenamiento del modelo\n",
    "\n",
    "Primero vamos a instanciar el modelo definiendo los hiperárametros por default y entrenaremos el modelo con el método *fit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-wallace",
   "metadata": {
    "id": "jEwul2-hhx5i"
   },
   "outputs": [],
   "source": [
    "# Importamos el modelo que utilizaremos. Regresión lineal\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-calibration",
   "metadata": {
    "id": "2msLxUbjh6Ue"
   },
   "outputs": [],
   "source": [
    "# Definimos un objeto con el modelo importado, en este caso los hiperparametros son por default por lo que el parentesis está vacio\n",
    "\n",
    "modelo = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-acrylic",
   "metadata": {
    "id": "0SzPV4tqh86A"
   },
   "outputs": [],
   "source": [
    "# Realizamos el entrenamiento del modelo con el método fit y los datos de entrenamiento \n",
    "\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-article",
   "metadata": {
    "id": "xzWoWJdRiAJX"
   },
   "outputs": [],
   "source": [
    "# Observamos los parámetros del modelo entrenado\n",
    "# Coeficiente (la pendiente de la recta)\n",
    "\n",
    "modelo.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-tyler",
   "metadata": {
    "id": "I_z-2KCCiAQX"
   },
   "outputs": [],
   "source": [
    "# Intercepto (el punto de comienzo de la recta en el eje y)\n",
    "\n",
    "modelo.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-addition",
   "metadata": {
    "id": "HuNAtRzQiJZ9"
   },
   "source": [
    "##### Testeo del modelo\n",
    "\n",
    "Utilizaramos el método *predict* para probar nuestro modelo con los datos de Testeo reservados previamente. Realizaremos la comparación del resultado de la predición de nuestro modelo con los datos conocidos.\n",
    "Utilizaremos la métrica **r2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-writer",
   "metadata": {
    "id": "j86tK68diMfD"
   },
   "outputs": [],
   "source": [
    "# Probamos nuestro modelo con predict y los datos de test\n",
    "\n",
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-presence",
   "metadata": {
    "id": "7u60OzJNiQTQ"
   },
   "outputs": [],
   "source": [
    "# Importamos una métrica para medir la performance modelo de regresión lineal: R2\n",
    "\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-tobacco",
   "metadata": {
    "id": "ei0EFWgOiWfk"
   },
   "outputs": [],
   "source": [
    "# Utilizamos R2 para medir la performance del modelo\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-gregory",
   "metadata": {
    "id": "EG0myRVfh0Pn"
   },
   "source": [
    "##### Entrenamiento del modelo cambiando el hiperparámetro\n",
    "\n",
    "Vamos a entrenar un segundo modelo de Regresión Lineal Multiple pero en este caso modificaremos el hiperparámetro *fit_intercept* para comparar los resultados con el modelo entrenado previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-folks",
   "metadata": {
    "id": "2msLxUbjh6Ue"
   },
   "outputs": [],
   "source": [
    "# Definimos un objeto con el modelo importado, en este caso los hiperparametros son por default por lo que el parentesis está vacio\n",
    "\n",
    "modelo_sin_inter = LinearRegression(fit_intercept=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-upset",
   "metadata": {
    "id": "0SzPV4tqh86A"
   },
   "outputs": [],
   "source": [
    "# Realizamos el entrenamiento del modelo con el método fit y los datos de entrenamiento \n",
    "\n",
    "modelo_sin_inter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-eagle",
   "metadata": {
    "id": "xzWoWJdRiAJX"
   },
   "outputs": [],
   "source": [
    "# Observamos los parámetros del modelo entrenado\n",
    "# Coeficiente (la pendiente de la recta)\n",
    "\n",
    "modelo_sin_inter.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-progress",
   "metadata": {
    "id": "I_z-2KCCiAQX"
   },
   "outputs": [],
   "source": [
    "# Intercepto (el punto de comienzo de la recta en el eje y)\n",
    "\n",
    "modelo_sin_inter.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-florida",
   "metadata": {
    "id": "HuNAtRzQiJZ9"
   },
   "source": [
    "##### Testeo del modelo\n",
    "\n",
    "Utilizaramos el método *predict* para probar nuestro modelo con los datos de Testeo reservados previamente. Realizaremos la comparación del resultado de la predición de nuestro modelo con los datos conocidos.\n",
    "Utilizaremos la métrica **r2** para poder comparar el resultado con el modelo entrenado anteriormente (sin intercepto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-orleans",
   "metadata": {
    "id": "j86tK68diMfD"
   },
   "outputs": [],
   "source": [
    "# Probamos nuestro modelo con predict y los datos de test\n",
    "\n",
    "y_pred_sin_inter = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-parish",
   "metadata": {
    "id": "ei0EFWgOiWfk"
   },
   "outputs": [],
   "source": [
    "# Utilizamos R2 para medir la performance del modelo\n",
    "\n",
    "r2_sin_inter = r2_score(y_test, y_pred_sin_inter)\n",
    "r2_sin_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El R2 del modelo con hiperparametros por default: \", round(r2,2))\n",
    "print(\"El R2 del modelo con hiperparametros fit_intercept=False: \", round(r2_sin_inter,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-tumor",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### ¿Qué podríamos hacer para mejorar estos resultados?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ejercicios optativos módulo 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
