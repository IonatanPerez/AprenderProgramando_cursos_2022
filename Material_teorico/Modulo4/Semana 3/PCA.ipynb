{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modular-cursor",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "[PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) un modelo de Aprendizaje No-Supervisado que se utiliza para la reducción de la dimensionalidad. A diferencia de los modelos No Supervisados vistos anteriormente, no buscamos agrupar los datos, sino transformarlos. Reorganizaremos la información de manera tal que no tendremos más las variables que tenemos actualmente, sino que las desarmamos y generamos componentes.\n",
    "\n",
    "Al igual que los modelos de aprendizaje no-supervisado vistos anteriormente, tiene los mismos pasos que el aprendizaje supervisado salvo por dos cuestiones: no se realiza la división de datos ni tampoco la evaluación.\n",
    "\n",
    "**No se realiza la división de los datos**, ya que no tenemos una variable a predecir **y** por lo cual no es necesario realizar esa división, tampoco se realiza la división en entrenamiento y testo porque no hay una predicción \"correcta\", sino solamente la forma de organizar los datos\n",
    "\n",
    "En este caso si es necesario utilizar el método *.transform* para transformar los datos luego de entrenar el modelo\n",
    "\n",
    "Por lo tanto los pasos que realizaremos son:\n",
    "1. Definición del Problema\n",
    "2. Búsqueda de datos \n",
    "3. Exploración y Limpieza de Datos\n",
    "4. Entrenamiento del modelo\n",
    "5. Transformar los datos\n",
    "\n",
    "##### Problema y Búsqueda de datos\n",
    "\n",
    "En primer lugar utilizaremos el Dataset de las Flores *Iris* visto en una clase anterior con el objetivo de poder graficarlo en 2 dimensiones. El Dataset está extraído de [Kaggle](https://www.kaggle.com/uciml/iris)\n",
    "\n",
    "Luego utilizaremos otro ejemplo para visualizar los que sucede cuando quitamos componentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerías que utilizaremos\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los primeros 3 registros\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-cleanup",
   "metadata": {},
   "source": [
    "#### Datos que utilizaremos para entrenar\n",
    "\n",
    "Quitamos en este ejemplo las columnas *Id* que no tiene utilizada y la columna *Species* que es la variable a predecir que no será parte de la reducción de la dimensionalidad, solo lo realizaremos con las variables predictoras que son numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos X que utilizaremso para realizar la reducción de dimensaionalidad\n",
    "\n",
    "X = data.drop(columns = [\"Id\", \"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modelo PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo PCA - Hiperparametro por default: todos los componentes principales\n",
    "\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rntrenamos el modelo\n",
    "\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los componentes\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T es para cambiar el sentido de los datos\n",
    "componentes = pca.components_.T\n",
    "componentes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame con los datos de los componentes para ver la relación con las variables originales\n",
    "\n",
    "pca_componentes = pd.DataFrame(componentes.T, index=X.columns, columns=['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "pca_componentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-african",
   "metadata": {},
   "source": [
    "#### Transformación de los datos\n",
    "\n",
    "Ya hemos entrenado el modelo, pero si queremos transformar los datos y crear un nuevo dataset debemos utilizar el método de la librería Scikit-Learn: fit_transform (que entrena y transforma los datos en la misma linea de código)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos los datos originales con el entrenamiento del modelo\n",
    "\n",
    "data_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con los datos transformados poniendo como indice la especie\n",
    "\n",
    "data_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2', 'PC3', 'PC4'],index=data[\"Species\"])\n",
    "data_pca.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "#data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-fitness",
   "metadata": {},
   "source": [
    "#### Visualización de los datos\n",
    "\n",
    "Realizaremos una visualización en 2 dimensiones con los componentes generados como resultado de nuestro entrenamiento, es decir en vez de usar las 4 variables que tenemos en el dataset original, utilizaremos los dos componenetes genereados como *ejes* *x* e *y* para poder realizar la visualización. Las *Species* se mantienen.\n",
    "\n",
    "En segundo lugar incluiremos en los gráficos como están formados los componenetes en base a las variables originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficaremos los datos del dataset Iris en 2 dimensiones\n",
    "\n",
    "plt.subplots(figsize = (10, 10))\n",
    "sns.scatterplot(data = data_pca, x = \"PC1\", y = \"PC2\", s=100, hue=data_pca.index.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (7, 7))\n",
    "\n",
    "# Hacemos un scatter de los datos en las dos primeras componentes\n",
    "sns.scatterplot(data = data_pca, x = \"PC1\", y = \"PC2\", s=100, hue=data_pca.index.tolist())\n",
    "\n",
    "# Ploteamos las líneas de referencia\n",
    "#plt.hlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "#plt.vlines(0,-3.5,3.5, linestyles='dotted', colors='grey')\n",
    "\n",
    "# Hacemos el grafico de las flechas indicando las direcciones de los features originales\n",
    "\n",
    "# Recorremos cada feature\n",
    "for i in range(len(features)):\n",
    "\n",
    "  # Creamos una flecha que vaya del origen y apunte en la dirección de los features\n",
    "  plt.arrow(0, 0, componentes.T[i][0], componentes.T[i][1], width = 0.05, alpha = 0.5)\n",
    "\n",
    "  # Indicamos con texto a qué feature corresponde cada flecha\n",
    "  plt.text(componentes.T[i][0], componentes.T[i][1], s = features[i], fontdict= {'color': 'k', 'size': 10})\n",
    "\n",
    "plt.xlabel('Primer componente principal')\n",
    "plt.ylabel('Segunda componente principal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-japanese",
   "metadata": {},
   "source": [
    "## PCA Caras\n",
    "\n",
    "Para poder tener otra visualización de lo que sucede al reducir la dimensionalidad y la pérdida o no de información que esto implica, utilizaremos un dataset de Caras importado directamente de la librearía Scikit-Learn. \n",
    "\n",
    "Cada una de las caras está descrito por un vector de 4096 píxeles. El Dataset está compuesto por 400 caras de 4096 features.\n",
    "\n",
    "El código es un poco más complejo pero vamos a centrarnos en las imágenes y las diferencias al modificar la cantidad de componentes que tenemos.\n",
    "\n",
    "Esta clase está basada en una Clase del Laboratorio de Datos - Facultad de Exactas - UBA http://materias.df.uba.ar/lda2021c1/171-2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-diana",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx9MBexj2Gft",
    "outputId": "68bed87b-2d0c-4ff7-efb3-ab7e7f8b27fc"
   },
   "outputs": [],
   "source": [
    "# Importamos el dataset de Scikit-Learn\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces # para cargar el dataset de caras\n",
    "data, targets = fetch_olivetti_faces(return_X_y = True) # cargamos las caras\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-factory",
   "metadata": {
    "id": "8TAgNw4RW8sO"
   },
   "source": [
    "##### Visualización de Caras\n",
    "\n",
    "Vamos a visualizar algunas caras al azar para ver como esta compuesto el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-threat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "W5IAkfbZmZvP",
    "outputId": "e5b2ed55-d709-4b8d-bd4e-5872a621461a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ploteo 25 imagenes al azar\n",
    "fig = plt.figure(figsize = (8,8)) # seteo el tamano de la figura\n",
    "for i in range(25):\n",
    "    j = np.random.randint(0, data.shape[0]) # en cada iteracion elijo un numero random entre 0 y la longitud de train_raw \n",
    "    plt.subplot(5,5,i+1) # Voy a tener una matriz de 5x5 subplots y voy llenando en la iteracion i-esima el subplot i+1\n",
    "    plt.imshow(data[j,:].reshape(64,64), interpolation='none', cmap=\"gray\") # plotea una imagen random, pues es la imagen j-esima del set de entrenamiento, en formato (28,28) para imagenes en escala de grises (tengo que reshapear)\n",
    "    plt.title(\"Persona: {}\".format(targets[j]), fontsize = 10) # pongo el titulo a los plots con el identificador unico de la persona \n",
    "    plt.xticks([]) # le saco los ticks en el eje X\n",
    "    plt.yticks([]) # le saco los ticks en el eje Y\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-biography",
   "metadata": {
    "id": "Eld6Or7EGy0x"
   },
   "source": [
    "#### Entrenamiento del modelo de PCA\n",
    "\n",
    "Vamos a realizar la reducción de dimensionalidad con 2 componentes para poder visualizar el dataset completo. La cantidad de componenentes es un hiperparámetro a definir al momento de instanciar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-train",
   "metadata": {
    "id": "Tp_8byJd3HRS"
   },
   "outputs": [],
   "source": [
    "# Intanciamos el modelo de PCA con 100 componentes\n",
    "pca = PCA(n_components =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-nursery",
   "metadata": {
    "id": "Tp_8byJd3HRS"
   },
   "outputs": [],
   "source": [
    "# Entrenamos los datos\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-merchant",
   "metadata": {
    "id": "Tp_8byJd3HRS"
   },
   "outputs": [],
   "source": [
    "# Transformamos los datos \n",
    "\n",
    "data_pca = pca.transform(data)\n",
    "\n",
    "# (esto puede ser realizado en una sola linea con el método .fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con los dos componentes principales solo para poder comprenderlo\n",
    "\n",
    "df_pca = pd.DataFrame(data_pca, columns=['PC1', 'PC2'])\n",
    "df_pca.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-paraguay",
   "metadata": {},
   "source": [
    "##### Visualización del dataset en 2 dimensiones\n",
    "\n",
    "Ahora que hemos reducido la dimensionalidad podemos graficar el dataset en 2 dimensiones, cada punto será una cara y el lugar que ocupa en el gráfico dependerá de las características que tiene. Luego observaremos algunas caras cercanas y alejadas para ver si encontramos un criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos nuestro dataset en 2 dimensiones\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "ax.scatter(data = df_pca, x = \"PC1\", y = \"PC2\")\n",
    "\n",
    "# Por cada dato escribimos a qué instancia corresponde\n",
    "for i in range(data.shape[0]):\n",
    "   ax.text(data_pca[i, 0], data_pca[i, 1], s = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos visualizar alguna cara en particular\n",
    "\n",
    "fig = plt.figure(figsize = (4,4)) # seteo el tamano de la figura\n",
    "plt.imshow(data[79,:].reshape(64,64), interpolation='none', cmap=\"gray\") # plotea una imagen random, pues es la imagen j-esima del set de entrenamiento, en formato (28,28) para imagenes en escala de grises (tengo que reshapear)\n",
    "plt.xticks([]) # le saco los ticks en el eje X\n",
    "plt.yticks([]) # le saco los ticks en el eje Y\n",
    "plt.show()\n",
    "\n",
    "#Ver distintos números y como son más diferentes o más parecidos de acuerdo al lugar en el espacio!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-encoding",
   "metadata": {
    "id": "-j9xjb8TAOPH"
   },
   "source": [
    "### PCA con 100 componentes\n",
    "\n",
    "Realizaremos la reducción de dimensionalidad con 100 componentes para observar cuánto se pierde en variabilidad y a su vez cómo cambia la resolución a medida que quitamos componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-weight",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmC3f5l2AdwJ",
    "outputId": "c272e49c-5ebb-4916-91db-d71bec832701"
   },
   "outputs": [],
   "source": [
    "# Intanciamos el modelo de PCA con hiperparametro 100 componentes\n",
    "pca_100 = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-knife",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmC3f5l2AdwJ",
    "outputId": "c272e49c-5ebb-4916-91db-d71bec832701"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo PCA con 100 componentes\n",
    "\n",
    "pca_100.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos los datos\n",
    "\n",
    "data_pca = pca_100.transform(data)\n",
    "data_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-covering",
   "metadata": {
    "id": "UJr7hwMqWklB"
   },
   "source": [
    "#### Varianza\n",
    "\n",
    "Es posible observar la variabilidad que aporta cada componente a los datos utilizando el atributo *explained_variance_ratio_* de Scikit Learn que indica el porcentaje de varianza explicada por cada uno de los componentes seleccionados.\n",
    "\n",
    "* la primera componente principal explica el 24% de la varianza de los datos\n",
    "\n",
    "* la segunda componente principal explica el 14% de la varianza de los datos\n",
    "\n",
    "* la tercera componente principal explica el 0.08% de la varianza de los datos\n",
    "\n",
    "* la cuarta componente principal explica el 0.04% de la varianza de los datos\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_100.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza \n",
    "\n",
    "sns.lineplot(x = range(len(pca_100.explained_variance_ratio_)), y = pca_100.explained_variance_ratio_)\n",
    "plt.ylabel('Fracción de varianza explicada')\n",
    "plt.xlabel('Número de componentes principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el acumulado con la función cumsum de numpy para poder graficar la acumulación \n",
    " \n",
    "varianza_acumulada = np.cumsum(pca_100.explained_variance_ratio_)\n",
    "\n",
    "varianza_acumulada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la varianza acumulada\n",
    "sns.lineplot(x = range(len(pca_100.explained_variance_ratio_)), y = np.cumsum(pca_100.explained_variance_ratio_))\n",
    "plt.ylabel('Fracción de varianza explicada')\n",
    "plt.xlabel('Número de componentes principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos en un mismo gráfico\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(pca_100.explained_variance_ratio_,  '-o', label='Componente individual')\n",
    "plt.plot(np.cumsum(pca_100.explained_variance_ratio_), '-s',label='Acumulado')\n",
    "plt.ylabel('Porcentaje de Varianza Explicada')\n",
    "plt.xlabel('Componentes Principales')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-saying",
   "metadata": {},
   "source": [
    "Si bien los datos tienen 4096 variables (pixeles), se alcanza el 90% de la información con 60 componentes principales, es decir que se reduce la dimensionalidad sin una pérdida significativa de información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-dutch",
   "metadata": {
    "id": "9ZqvjySdBz-z"
   },
   "source": [
    "#### Visualización de caras cambiando componentes principales\n",
    "\n",
    "Vamos a comparar una misma cara como se ve a medida que quitamos componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-foundation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "gENknHT37-6A",
    "outputId": "f6faa9dd-f07b-46ae-b31d-544fb152be25"
   },
   "outputs": [],
   "source": [
    "# Elegimos una cara de ejemplo para ver como se ve original\n",
    "figura = 10\n",
    "\n",
    "plt.imshow(data[figura, :].reshape(64, 64), interpolation='none', cmap=\"gray\") # plotea la imagen de índice faceid en formato (28,28) para imagenes en escala de grises (tengo que reshapear)\n",
    "#plt.xticks([]) # le saco el eje X\n",
    "#plt.yticks([]) # le saco el eje Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-detroit",
   "metadata": {},
   "source": [
    "Visualizamos la cara luego de realizar la reducción de dimensionalidad a 100 componentes utilizando el atributo *inverse_transform* de Sckit-Learn que transforma la data de nuevo a su espacio original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos la cara seleccionada\n",
    "figura = 10\n",
    "\n",
    "# Reconstrucción de la cara desde el espacio reducido!!!\n",
    "X_r = pca_100.inverse_transform(data_pca)\n",
    "\n",
    "\n",
    "plt.imshow(X_r[figura, :].reshape(64, 64), interpolation='none', cmap=\"gray\") # plotea la imagen de índice faceid en formato (28,28) para imagenes en escala de grises (tengo que reshapear)\n",
    "#plt.xticks([]) # le saco el eje X\n",
    "#plt.yticks([]) # le saco el eje Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a realizar la misma acción pero cambiando la cantidad de componentes. Ejemplo: 200, 50, 1, 400!!\n",
    "\n",
    "#instanciamos el modelo cambiando la cantidad de componenetes\n",
    "pca = PCA (n_components=200)\n",
    "\n",
    "#entrenamos el modelo y transformamos los datos\n",
    "data_pca = pca.fit_transform(data)\n",
    "\n",
    "# Reconstruimos la cara con el espacio reducido\n",
    "pca_inverse = pca.inverse_transform(data_pca)\n",
    "\n",
    "#Visualizamos\n",
    "plt.imshow(pca_inverse[figura, :].reshape(64, 64), interpolation='none', cmap=\"gray\") # plotea la imagen de índice faceid en formato (28,28) para imagenes en escala de grises (tengo que reshapear)\n",
    "#plt.xticks([]) # le saco el eje X\n",
    "#plt.yticks([]) # le saco el eje Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-conservation",
   "metadata": {
    "id": "xfAru54ffuK9"
   },
   "source": [
    "Cuanto más componentes principales, mejor será la reproducción de la cara original. Igualmente con pocas componentes (con muchas menos que la cantidad de features del espacio original) ya se pueden ver imagenes parecidas a la original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
